{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "def get_unigrams(file_name):\n",
    "    unigrams = {}\n",
    "    count = 0\n",
    "    with io.open(file_name, encoding='utf8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            tokens = line.strip().split()\n",
    "            count+=1\n",
    "            for token in tokens:\n",
    "                token = token.lower()\n",
    "                try:\n",
    "                    unigrams[token]\n",
    "                except:\n",
    "                    unigrams[token] = 0\n",
    "                unigrams[token] += 1\n",
    "                \n",
    "    return unigrams\n",
    "\n",
    "def index_unigrams(unigrams):\n",
    "    new_unigrams = {}\n",
    "    reverse_unigrams = {}\n",
    "    for index, unigram in enumerate(unigrams):\n",
    "        new_unigrams[unigram] = index\n",
    "        reverse_unigrams[index] = unigram\n",
    "    return new_unigrams, reverse_unigrams\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 26256)\n"
     ]
    }
   ],
   "source": [
    "file_name = \"NNN/sample_corpus/sample_corpus.txt\"\n",
    "import nltk\n",
    "import copy\n",
    "unigrams = get_unigrams(file_name)\n",
    "words = [i for i in unigrams.keys()]\n",
    "pos = nltk.pos_tag(words)\n",
    "verbs = [i[0] for i in pos if i[1]=='VB' or i[1]=='VBD' or i[1]=='VBG' or i[1]=='VBN' or i[1]=='VBP' or i[1]=='VBZ']\n",
    "iunigrams,runigrams = index_unigrams(unigrams)\n",
    "unigrams = sorted(unigrams.items(), key = lambda x: x[1], reverse = True )\n",
    "print (unigrams[0])\n",
    "#unigrams = [i for i in unigrams if i[0] in verbs]\n",
    "from pprint import pprint\n",
    "#pprint.pprint(iunigrams) # Figure out non-stop words\n",
    "dimensions = [x[0] for x in unigrams[100:3100]]\n",
    "# count = 0\n",
    "# dimensions = list()\n",
    "# for x in unigrams[100:]:\n",
    "#     if x[0] in verbs:\n",
    "#         dimensions.append(x[0])\n",
    "#         count += 1\n",
    "#     if count == 3000:\n",
    "#         break\n",
    "idimensions = {x: index for index, x in enumerate(dimensions)}\n",
    "#pprint(dimensions)\n",
    "# print(dimensions.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43124, 6000)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "cmatrix = numpy.memmap(\"lsa.cmatrix\", dtype='float64', mode='w+', shape=(len(unigrams),len(dimensions)))\n",
    "print(cmatrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def populate_cmatrix(file_name, cmatrix, iunigrams, dimensions, window = 5):\n",
    "     e = 0\n",
    "     s = 0\n",
    "     with open(file_name, encoding='utf-8', errors='ignore') as f:\n",
    "\n",
    "        count = 0\n",
    "        for index, line in enumerate(f):\n",
    "            tokens = line.strip().split()\n",
    "            posTokens = nltk.pos_tag(tokens)\n",
    "            postokens = [i[0] for i in posTokens if i[1]=='VB' or i[1]=='VBD' or i[1]=='VBG' or i[1]=='VBN' or i[1]=='VBP' or i[1]=='VBZ']\n",
    "            count+=1\n",
    "            for indexj, token in enumerate(tokens):\n",
    "                token = token.lower()\n",
    "                lcontext = tokens[indexj - window:indexj]\n",
    "                rcontext = tokens[indexj + 1:index + window]\n",
    "                context = [tok.lower() for tok in lcontext + rcontext]\n",
    "                \n",
    "                try:\n",
    "                    unigram_index = iunigrams[token]                    \n",
    "                    for d in context:\n",
    "                        \n",
    "                        if d in dimensions:\n",
    "                            j = dimensions[d]\n",
    "                            cmatrix[unigram_index][j] += 1\n",
    "#                     for d in context:\n",
    "                        \n",
    "#                         if d in dimensions:\n",
    "#                             j = dimensions[d]\n",
    "#                             cmatrix[unigram_index][1500+j] += 1\n",
    "                            s += 1                          \n",
    "                except:\n",
    "                    e += 1\n",
    "            \n",
    "            \n",
    "     print(e,s)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 769283\n",
      "40.21617412567139\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "s = time()\n",
    "populate_cmatrix(file_name, cmatrix, iunigrams, idimensions)\n",
    "e = time()\n",
    "print(e -s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12636 5130 191 816 8607\n",
      "[ 0.  0.  0. ...,  0.  0.  0.] [ 0.  0.  3. ...,  0.  0.  0.] [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "41.677331968349414\n",
      "0.920444271582\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#boy, sunday, eat, good, slowly, 100 \n",
    "w1 = 'boy'\n",
    "w2 = 'sunday'\n",
    "w3 = 'eat'\n",
    "w4 = 'good'\n",
    "w5 = 'slowly'\n",
    "w6 = '100'\n",
    "id1 = iunigrams[w1]\n",
    "id2 = iunigrams[w2]\n",
    "id3 = iunigrams[w3]\n",
    "id4 = iunigrams[w4]\n",
    "id5 = iunigrams[w5]\n",
    "id6 = iunigrams[w6]\n",
    "print(id1, id2, id3, id4, id5)\n",
    "v1 = cmatrix[id1]\n",
    "v2 = cmatrix[id2]\n",
    "v3 = cmatrix[id3]\n",
    "\n",
    "print(v1, v2, v3)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import *\n",
    "print(euclidean(v1, v2))\n",
    "print(cosine(v1,v2))\n",
    "a = ((v1.dot(v1))/(numpy.linalg.norm(v1)*numpy.linalg.norm(v1)))\n",
    "print (1-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.25409913063049\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "s = time()\n",
    "svd = TruncatedSVD(n_components=100, random_state=42)\n",
    "svd.fit(cmatrix)\n",
    "twod_cmatrix = svd.transform(cmatrix)\n",
    "e = time()\n",
    "print(e - s )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boy', 'sunday', 'eat', 'good', 'slowly', '100']\n",
      "boy 1.11022302463e-16 1.11022302463e-16\n",
      "['ou', 'mens', 'widow', 'son', 'bullies', 'janet', 'carrier', 'flat', 'dogged', 'lap']\n",
      "sunday 1.11022302463e-16 1.11022302463e-16\n",
      "['last', 'spoke', 'week', 'the', 'his', 'at', 'elections', 'on', 'deal', ',']\n",
      "eat 0.0 1.11022302463e-16\n",
      "['spilled', 'peterborough', 'humorous', '2.2.4ac1', 'hoylake', 'joking', 'videotape', 'eventing', 'breisner', 'handball']\n",
      "good 0.0 1.11022302463e-16\n",
      "['it', 'way', 'but', 'find', 'say', 'like', 'then', 'now', 'get', 'so']\n",
      "slowly -2.22044604925e-16 1.11022302463e-16\n",
      "['executives', 'emissions', 'fuels', 'dioxide', 'balanced', 'commanders', 'controversies', 'c.i.a.', 'pentagon', 'iran']\n",
      "100 -4.4408920985e-16 1.11022302463e-16\n",
      "['=', '10', 'centimetres', 'sq.', 'metric', 'millimetres', 'centimetre', 'decimeter', 'decimetres', 'decametres']\n"
     ]
    }
   ],
   "source": [
    "v1_2d, v2_2d, v3_2d, v4_2d, v5_2d, v6_2d = twod_cmatrix[id1], twod_cmatrix[id2], twod_cmatrix[id3], twod_cmatrix[id4], twod_cmatrix[id5], twod_cmatrix[id6]\n",
    "print ([runigrams[j] for i,j in enumerate([id1,id2,id3,id4,id5,id6])])\n",
    "def getTen(vec):\n",
    "    cosi = []\n",
    "    for i in range(len(twod_cmatrix)):\n",
    "        if numpy.linalg.norm(twod_cmatrix[i]) == 0:\n",
    "            continue\n",
    "        cosi.append((i,cosine(twod_cmatrix[i],vec)))\n",
    "    cosi = sorted(cosi,key=lambda x: x[1])\n",
    "    print (runigrams[cosi[0][0]],cosi[0][1], cosine(v1_2d,v1_2d))\n",
    "    return [i[0] for i in cosi[1:11]]\n",
    "for i in [v1_2d, v2_2d, v3_2d, v4_2d, v5_2d, v6_2d]:\n",
    "    indx = getTen(i)\n",
    "    print ([runigrams[i] for i in indx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "v1_2d = v1_2d / numpy.linalg.norm(v1_2d)\n",
    "v2_2d = v2_2d / numpy.linalg.norm(v2_2d)\n",
    "v3_2d = v3_2d / numpy.linalg.norm(v3_2d)\n",
    "print ([v1_2d, v2_2d,v3_2d])\n",
    "colors = ['r','b','g']\n",
    "fig, axs = plt.subplots(1,1)\n",
    "for i, x in enumerate([v1_2d, v2_2d,v3_2d]):\n",
    "    a = plt.plot([0,x[0]],[0,x[1]],colors[i]+'-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'twod_cmatrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b59e4bc3f734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwod_cmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtwod_cmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'twod_cmatrix' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=20,n_init=100,verbose=True)\n",
    "temp = kmeans.fit(twod_cmatrix)\n",
    "print (twod_cmatrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kmeans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6e10eae411aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'kmeans' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print (len(kmeans.cluster_centers_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
